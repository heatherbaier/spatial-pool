{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd06e6e7e11ff29b7ea88d93fdd1bf54ac8bd20e793b837d22d51eef8412ed09bee",
   "display_name": "Python 3.7.10 64-bit ('caoe': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/hbaier/anaconda3/envs/caoe/lib/python3.7/site-packages/geopandas/_compat.py:110: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.0-CAPI-1.16.2). Conversions between both will be slow.\n  shapely_geos_version, geos_capi_version_string\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import landsat_prep as lp\n",
    "import geograph as gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl = gg.ImageGraphLoader(\"./data/\", \"MEX\", \"./migration_data.json\", 1)#.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "class resnet18_mod(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, resnet):\n",
    "        super().__init__()\n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        self.avgpool = resnet.avgpool\n",
    "        self.fc = resnet.fc\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.flatten(start_dim=1)\n",
    "        # out = torch.cat((out, ids, coords), dim = 1)\n",
    "        # out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-36f29379df57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr18\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet18_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.detach().numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "r18 = models.resnet18(pretrained = True)\n",
    "model = resnet18_mod(r18)\n",
    "input = model(final_im)#.detach().numpy()\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCN basic operation\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, bias=True):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.weight = nn.Parameter(torch.rand(input_dim, output_dim))#.cuda())\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.rand(output_dim))#.cuda())\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        y = torch.matmul(adj, x)\n",
    "        y = torch.matmul(y, self.weight)\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "        return y\n",
    "\n",
    "# Generate Assignment Matrix\n",
    "class GenAssign(nn.Module):\n",
    "    def __init__(self, input_dim, num_clusters, bias=True):\n",
    "        super(GenAssign, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_clusters = num_clusters\n",
    "        self.weight = nn.Parameter(torch.rand(input_dim, num_clusters))#.cuda())\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.rand(num_clusters))#.cuda())\n",
    "        else:\n",
    "            self.bias = None\n",
    "        # self.linear = torch.nn.Linear(input_dim, num_clusters)\n",
    "        self.sm = torch.nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        y = torch.matmul(adj, x)\n",
    "        y = torch.matmul(y, self.weight)\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "        # y = self.linear(y)\n",
    "        y = self.sm(y)\n",
    "        _, i = torch.max(y, 1)\n",
    "        return i\n",
    "\n",
    "\n",
    "# Pool based on clusters\n",
    "class PoolClusters(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoolClusters, self).__init__()\n",
    "\n",
    "    def forward(self, x, sl):\n",
    "        cluster_ids = torch.unique(sl)\n",
    "        for cluster in cluster_ids:\n",
    "            indices = torch.nonzero(sl == cluster, as_tuple = True)[0]\n",
    "            cluster_mean = torch.mean(torch.index_select(x, 0, indices), dim = 0).unsqueeze(0)\n",
    "            try:\n",
    "                out = torch.cat((out, cluster_mean))\n",
    "            except Exception as e:\n",
    "                out = cluster_mean\n",
    "        return out\n",
    "\n",
    "\n",
    "def make_edge_list(neighbors_dict):\n",
    "    edge_list = []\n",
    "    for k,v in neighbors_dict.items():\n",
    "        [edge_list.append([k, cur_v]) for cur_v in v]\n",
    "    return edge_list\n",
    "\n",
    "def make_adj_matrix(edge_list, dim):\n",
    "    adj_matrix = np.zeros((dim, dim))\n",
    "    for edge in edge_list:\n",
    "        adj_matrix[edge[0]][edge[1]] = 1\n",
    "    for i in range(dim):\n",
    "        adj_matrix[i][i] = 1\n",
    "\n",
    "    return adj_matrix\n",
    "\n",
    "\n",
    "def fix_sl(sl):\n",
    "    cluster_ids = torch.unique(sl)\n",
    "    ref = dict(zip([i.item() for i in cluster_ids], [i for i in range(len(cluster_ids))]))\n",
    "    for i in cluster_ids:\n",
    "        sl[sl == i.item()] = ref[i.item()]\n",
    "    return sl\n",
    "\n",
    "\n",
    "# GCN basic operation\n",
    "class GenAdj(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GenAdj, self).__init__()\n",
    "\n",
    "    def forward(self, adj, sl, neighbors_dict):\n",
    "\n",
    "        sl = fix_sl(sl)\n",
    "\n",
    "        adj_map, new_neighbors_dict = {}, {}\n",
    "        cluster_ids = torch.unique(sl)\n",
    "\n",
    "        # Create a dictionary where each key is a node and the value is the cluster it belongs to\n",
    "        for cluster in cluster_ids:\n",
    "            indices = torch.nonzero(sl == cluster, as_tuple = True)[0]\n",
    "            for i in indices:\n",
    "                if i not in adj_map.keys():\n",
    "                    adj_map[i.item()] = cluster.item()\n",
    "\n",
    "        # Create a new neighbors dictionary for each of the clusters\n",
    "        for cluster in cluster_ids:\n",
    "            indices = torch.nonzero(sl == cluster, as_tuple = True)[0]\n",
    "\n",
    "            for i in indices:\n",
    "                temp = []\n",
    "                [temp.append(adj_map[i]) for i in neighbors_dict[i.item()] if i not in temp]\n",
    "                temp = list(set(temp)) # TO-DO: HERE CREATE SOME SORT OF SECONDARY DICTIONARY OR SOMETHING THAT COUNTS HOW MANY EDGES TO CREATE WEIGHTED ADJ MATRIX\n",
    "\n",
    "                new_neighbors_dict[cluster.item()] = temp\n",
    "\n",
    "        edge_list = make_edge_list(new_neighbors_dict)\n",
    "        adj_matrix = make_adj_matrix(edge_list, len(cluster_ids))\n",
    "\n",
    "        return torch.tensor(adj_matrix, dtype = torch.float32), new_neighbors_dict\n",
    "\n",
    "\n",
    "class diffPool(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_clusters, bias=True):\n",
    "        super(diffPool, self).__init__()\n",
    "\n",
    "        self.gc = GraphConv(input_dim = input_dim, output_dim = output_dim)\n",
    "        self.bn = torch.nn.BatchNorm1d(output_dim)\n",
    "        self.gen_assign = GenAssign(input_dim = output_dim, num_clusters = num_clusters)\n",
    "        self.pool = PoolClusters()\n",
    "        self.gen_adj = GenAdj()\n",
    "\n",
    "    def forward(self, x, adj, neighbors_dict):\n",
    "\n",
    "        # Generate node embeddings & normalize (no pooling yet)\n",
    "        x = self.gc(x, torch.tensor(adj, dtype = torch.float32))\n",
    "        x = self.bn(x)\n",
    "        # Create the assignment matrix (i.e. assign each node to a cluster)\n",
    "        sl = self.gen_assign(x, adj)\n",
    "        # Create the pooled feature matrix\n",
    "        x = self.pool(x, sl)\n",
    "        # Generate the new adjacency matrix\n",
    "        adj, neighbors_dict = self.gen_adj(adj, sl, neighbors_dict)\n",
    "        # print(neighbors_dict)\n",
    "\n",
    "        return x, adj, neighbors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diffPool(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_clusters, bias=True):\n",
    "        super(diffPool, self).__init__()\n",
    "\n",
    "        self.gc = GraphConv(input_dim = input_dim, output_dim = output_dim)\n",
    "        self.bn = torch.nn.BatchNorm1d(output_dim)\n",
    "        self.gen_assign = GenAssign(input_dim = output_dim, num_clusters = num_clusters)\n",
    "        self.pool = PoolClusters()\n",
    "        self.gen_adj = GenAdj()\n",
    "\n",
    "    def forward(self, x, adj, neighbors_dict):\n",
    "\n",
    "        # Generate node embeddings & normalize (no pooling yet)\n",
    "        x = self.gc(x, torch.tensor(adj, dtype = torch.float32))\n",
    "        if x.shape[0] > 1:\n",
    "            x = self.bn(x)\n",
    "\n",
    "        # print(x.shape)\n",
    "        # Create the assignment matrix (i.e. assign each node to a cluster)\n",
    "        sl = self.gen_assign(x, adj)\n",
    "        # Create the pooled feature matrix\n",
    "        x = self.pool(x, sl)\n",
    "        # Generate the new adjacency matrix\n",
    "        adj, neighbors_dict = self.gen_adj(adj, sl, neighbors_dict)\n",
    "        # print(neighbors_dict)\n",
    "\n",
    "        return x, adj, neighbors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spatialPool(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_clusters, resnet, bias=True):\n",
    "        super(spatialPool, self).__init__()\n",
    "\n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        self.avgpool = resnet.avgpool\n",
    "\n",
    "        self.dp1 = diffPool(input_dim = input_dim, output_dim = output_dim, num_clusters = 4)\n",
    "        self.dp2 = diffPool(input_dim = output_dim, output_dim = 128, num_clusters = 2)\n",
    "        self.dp3 = diffPool(input_dim = 128, output_dim = 256, num_clusters = 1)\n",
    "        self.linear = torch.nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x, adj, neighbors_dict):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        x, adj, neighbors_dict = self.dp1(x, adj, neighbors_dict)\n",
    "        x, adj, neighbors_dict = self.dp2(x, adj, neighbors_dict)\n",
    "        x, adj, neighbors_dict = self.dp3(x, adj, neighbors_dict)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PRED:  -0.04   |  LOSS:  42055.04\n",
      "PRED:  10.67   |  LOSS:  3406.33\n",
      "PRED:  0.1   |  LOSS:  11991.9\n",
      "PRED:  30.11   |  LOSS:  3690.89\n",
      "12228.830615234376 \n",
      "\n",
      "PRED:  -0.01   |  LOSS:  42055.01\n",
      "PRED:  58.56   |  LOSS:  3358.44\n",
      "PRED:  0.66   |  LOSS:  11991.34\n",
      "PRED:  96.48   |  LOSS:  3624.52\n",
      "12205.862841796876 \n",
      "\n",
      "PRED:  0.01   |  LOSS:  42054.99\n",
      "PRED:  144.51   |  LOSS:  3272.49\n",
      "PRED:  1.43   |  LOSS:  11990.57\n",
      "PRED:  1.67   |  LOSS:  3719.33\n",
      "12207.474951171875 \n",
      "\n",
      "PRED:  0.03   |  LOSS:  42054.97\n",
      "PRED:  258.51   |  LOSS:  3158.49\n",
      "PRED:  2.45   |  LOSS:  11989.55\n",
      "PRED:  328.45   |  LOSS:  3392.55\n",
      "12119.1119140625 \n",
      "\n",
      "PRED:  0.05   |  LOSS:  42054.95\n",
      "PRED:  413.19   |  LOSS:  3003.81\n",
      "PRED:  3.76   |  LOSS:  11988.24\n",
      "PRED:  513.19   |  LOSS:  3207.81\n",
      "12050.96201171875 \n",
      "\n",
      "PRED:  0.07   |  LOSS:  42054.93\n",
      "PRED:  629.06   |  LOSS:  2787.94\n",
      "PRED:  5.39   |  LOSS:  11986.61\n",
      "PRED:  5.86   |  LOSS:  3715.14\n",
      "12108.9216796875 \n",
      "\n",
      "PRED:  6.37   |  LOSS:  42048.63\n",
      "PRED:  881.89   |  LOSS:  2535.11\n",
      "PRED:  7.49   |  LOSS:  11984.51\n",
      "PRED:  8.1   |  LOSS:  3712.9\n",
      "12056.23134765625 \n",
      "\n",
      "PRED:  8.73   |  LOSS:  42046.27\n",
      "PRED:  1154.59   |  LOSS:  2262.41\n",
      "PRED:  10.1   |  LOSS:  11981.9\n",
      "PRED:  10.84   |  LOSS:  3710.16\n",
      "12000.146435546874 \n",
      "\n",
      "PRED:  11.6   |  LOSS:  42043.4\n",
      "PRED:  1455.08   |  LOSS:  1961.92\n",
      "PRED:  13.22   |  LOSS:  11978.78\n",
      "PRED:  1633.36   |  LOSS:  2087.64\n",
      "11614.345849609375 \n",
      "\n",
      "PRED:  15.03   |  LOSS:  42039.97\n",
      "PRED:  1844.88   |  LOSS:  1572.12\n",
      "PRED:  17.01   |  LOSS:  11974.99\n",
      "PRED:  2087.76   |  LOSS:  1633.24\n",
      "11444.064794921875 \n",
      "\n",
      "PRED:  0.15   |  LOSS:  42054.84\n",
      "PRED:  2360.95   |  LOSS:  1056.05\n",
      "PRED:  21.31   |  LOSS:  11970.69\n",
      "PRED:  22.45   |  LOSS:  3698.55\n",
      "11756.02763671875 \n",
      "\n",
      "PRED:  0.18   |  LOSS:  42054.82\n",
      "PRED:  2930.94   |  LOSS:  486.06\n",
      "PRED:  25.91   |  LOSS:  11966.08\n",
      "PRED:  3240.94   |  LOSS:  480.06\n",
      "10997.406787109376 \n",
      "\n",
      "PRED:  0.21   |  LOSS:  42054.79\n",
      "PRED:  3591.24   |  LOSS:  174.24\n",
      "PRED:  30.54   |  LOSS:  11961.46\n",
      "PRED:  31.47   |  LOSS:  3689.53\n",
      "11576.004150390625 \n",
      "\n",
      "PRED:  0.24   |  LOSS:  42054.76\n",
      "PRED:  3904.47   |  LOSS:  487.47\n",
      "PRED:  33.97   |  LOSS:  11958.03\n",
      "PRED:  34.63   |  LOSS:  3686.37\n",
      "11637.327197265626 \n",
      "\n",
      "PRED:  0.27   |  LOSS:  42054.73\n",
      "PRED:  3905.71   |  LOSS:  488.71\n",
      "PRED:  36.4   |  LOSS:  11955.6\n",
      "PRED:  36.84   |  LOSS:  3684.16\n",
      "11636.64052734375 \n",
      "\n",
      "PRED:  37.37   |  LOSS:  42017.63\n",
      "PRED:  3717.22   |  LOSS:  300.22\n",
      "PRED:  38.23   |  LOSS:  11953.77\n",
      "PRED:  38.58   |  LOSS:  3682.42\n",
      "11590.80859375 \n",
      "\n",
      "PRED:  39.0   |  LOSS:  42016.0\n",
      "PRED:  3429.1   |  LOSS:  12.1\n",
      "PRED:  39.64   |  LOSS:  11952.36\n",
      "PRED:  3245.22   |  LOSS:  475.78\n",
      "10891.245849609375 \n",
      "\n",
      "PRED:  40.36   |  LOSS:  42014.64\n",
      "PRED:  3183.86   |  LOSS:  233.14\n",
      "PRED:  41.63   |  LOSS:  11950.37\n",
      "PRED:  42.42   |  LOSS:  3678.58\n",
      "11575.346875 \n",
      "\n",
      "PRED:  0.34   |  LOSS:  42054.66\n",
      "PRED:  3238.23   |  LOSS:  178.77\n",
      "PRED:  44.91   |  LOSS:  11947.09\n",
      "PRED:  45.89   |  LOSS:  3675.11\n",
      "11571.12607421875 \n",
      "\n",
      "PRED:  46.88   |  LOSS:  42008.12\n",
      "PRED:  3420.72   |  LOSS:  3.72\n",
      "PRED:  48.52   |  LOSS:  11943.48\n",
      "PRED:  49.18   |  LOSS:  3671.82\n",
      "11525.427001953125 \n",
      "\n",
      "PRED:  0.37   |  LOSS:  42054.62\n",
      "PRED:  3394.55   |  LOSS:  22.45\n",
      "PRED:  0.39   |  LOSS:  11991.61\n",
      "PRED:  52.23   |  LOSS:  3668.77\n",
      "11547.491748046876 \n",
      "\n",
      "PRED:  0.4   |  LOSS:  42054.6\n",
      "PRED:  3527.32   |  LOSS:  110.32\n",
      "PRED:  54.24   |  LOSS:  11937.76\n",
      "PRED:  54.68   |  LOSS:  3666.32\n",
      "11553.798583984375 \n",
      "\n",
      "PRED:  0.44   |  LOSS:  42054.57\n",
      "PRED:  3464.82   |  LOSS:  47.82\n",
      "PRED:  0.45   |  LOSS:  11991.55\n",
      "PRED:  3362.36   |  LOSS:  358.64\n",
      "10890.515234375 \n",
      "\n",
      "PRED:  0.47   |  LOSS:  42054.53\n",
      "PRED:  3358.91   |  LOSS:  58.09\n",
      "PRED:  0.49   |  LOSS:  11991.51\n",
      "PRED:  3432.9   |  LOSS:  288.1\n",
      "10878.44580078125 \n",
      "\n",
      "PRED:  0.51   |  LOSS:  42054.48\n",
      "PRED:  3570.9   |  LOSS:  153.9\n",
      "PRED:  59.87   |  LOSS:  11932.13\n",
      "PRED:  0.55   |  LOSS:  3720.45\n",
      "11572.19248046875 \n",
      "\n",
      "PRED:  60.75   |  LOSS:  41994.25\n",
      "PRED:  3630.73   |  LOSS:  213.73\n",
      "PRED:  61.36   |  LOSS:  11930.64\n",
      "PRED:  0.59   |  LOSS:  3720.41\n",
      "11571.80625 \n",
      "\n",
      "PRED:  61.77   |  LOSS:  41993.23\n",
      "PRED:  3526.92   |  LOSS:  109.92\n",
      "PRED:  61.97   |  LOSS:  11930.03\n",
      "PRED:  0.62   |  LOSS:  3720.38\n",
      "11550.714404296876 \n",
      "\n",
      "PRED:  62.01   |  LOSS:  41992.99\n",
      "PRED:  3324.05   |  LOSS:  92.95\n",
      "PRED:  62.61   |  LOSS:  11929.39\n",
      "PRED:  0.65   |  LOSS:  3720.35\n",
      "11547.137548828125 \n",
      "\n",
      "PRED:  63.63   |  LOSS:  41991.37\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a402b48089db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/caoe/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/caoe/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r18 = models.resnet18(pretrained = True)\n",
    "model = spatialPool(input_dim = 512, output_dim = 256, num_clusters = 4, resnet = r18)\n",
    "criterion = torch.nn.L1Loss(reduction = \"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "final_im = gl.data[0].x\n",
    "adj = gl.data[0].adj_matrix\n",
    "neighbors_dict = gl.data[0].neighbors\n",
    "y = gl.data[0].y\n",
    "batch = gl.data[0].batch\n",
    "\n",
    "for epoch in range(0, 50):  \n",
    "\n",
    "    running_loss, c = 0, 1\n",
    "\n",
    "    for i in range(0, 4):\n",
    "\n",
    "        final_im = gl.data[i].x\n",
    "        adj = gl.data[i].adj_matrix\n",
    "        neighbors_dict = gl.data[i].neighbors\n",
    "        y = gl.data[i].y\n",
    "        batch = gl.data[i].batch\n",
    "\n",
    "        \n",
    "\n",
    "        pred = model(final_im, torch.tensor(adj, dtype = torch.float32), neighbors_dict)\n",
    "        # print(pred)\n",
    "        loss = criterion(pred, torch.tensor([y]))\n",
    "\n",
    "        print(\"PRED: \", round(pred.item(), 2),  \"  |  LOSS: \", round(loss.item(), 2))\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        c += 1\n",
    "\n",
    "    print(running_loss / c, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[5055.0986]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}