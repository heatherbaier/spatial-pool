{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd06e6e7e11ff29b7ea88d93fdd1bf54ac8bd20e793b837d22d51eef8412ed09bee",
   "display_name": "Python 3.7.10 64-bit ('caoe': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.array([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.],\n",
    "       [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
    "       [0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.],\n",
    "       [0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
    "       [0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.]])\n",
    "\n",
    "\n",
    "neighbors_dict = {0: [1, 2],\n",
    "                  1: [0, 2, 4, 5],\n",
    "                  2: [0, 1, 3, 4, 5, 6],\n",
    "                  3: [2, 5, 6],\n",
    "                  4: [1, 2, 5, 7, 8],\n",
    "                  5: [1, 2, 3, 4, 6, 7, 8, 9],\n",
    "                  6: [2, 3, 5, 8, 9],\n",
    "                  7: [4, 5, 8, 10],\n",
    "                  8: [4, 5, 6, 7, 9, 10, 11],\n",
    "                  9: [5, 6, 8, 10, 11],\n",
    "                  10: [7, 8, 9, 11, 12],\n",
    "                  11: [8, 9, 10, 12],\n",
    "                  12: [10, 11]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 3, 256, 256])\ntorch.Size([2, 3, 256, 256])\ntorch.Size([3, 3, 256, 256])\ntorch.Size([4, 3, 256, 256])\ntorch.Size([5, 3, 256, 256])\ntorch.Size([6, 3, 256, 256])\ntorch.Size([7, 3, 256, 256])\ntorch.Size([8, 3, 256, 256])\ntorch.Size([9, 3, 256, 256])\ntorch.Size([10, 3, 256, 256])\ntorch.Size([11, 3, 256, 256])\ntorch.Size([12, 3, 256, 256])\ntorch.Size([13, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, utils, models\n",
    "\n",
    "to_tens = transforms.ToTensor()\n",
    "# del final_im\n",
    "\n",
    "for im in os.listdir(\"/home/hbaier/Desktop/graphPool/imagery\"):\n",
    "    cur_im = to_tens(Image.open(os.path.join(\"/home/hbaier/Desktop/graphPool/imagery\", im)).convert(\"RGB\")).unsqueeze(0)\n",
    "    try:\n",
    "        final_im = torch.cat((final_im, cur_im), dim = 0)\n",
    "        # print(\"try\")\n",
    "    except Exception as e:\n",
    "        final_im = cur_im\n",
    "        # print(e)\n",
    "    print(final_im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "class resnet18_mod(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, resnet):\n",
    "        super().__init__()\n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        self.avgpool = resnet.avgpool\n",
    "        self.fc = resnet.fc\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.flatten(start_dim=1)\n",
    "        # out = torch.cat((out, ids, coords), dim = 1)\n",
    "        # out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([13, 512])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "r18 = models.resnet18(pretrained = True)\n",
    "model = resnet18_mod(r18)\n",
    "input = model(final_im)#.detach().numpy()\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCN basic operation\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, bias=True):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.weight = nn.Parameter(torch.rand(input_dim, output_dim))#.cuda())\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.rand(output_dim))#.cuda())\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        y = torch.matmul(adj, x)\n",
    "        y = torch.matmul(y, self.weight)\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "        return y\n",
    "\n",
    "# Generate Assignment Matrix\n",
    "class GenAssign(nn.Module):\n",
    "    def __init__(self, input_dim, num_clusters, bias=True):\n",
    "        super(GenAssign, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_clusters = num_clusters\n",
    "        self.weight = nn.Parameter(torch.rand(input_dim, num_clusters))#.cuda())\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.rand(num_clusters))#.cuda())\n",
    "        else:\n",
    "            self.bias = None\n",
    "        # self.linear = torch.nn.Linear(input_dim, num_clusters)\n",
    "        self.sm = torch.nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        y = torch.matmul(adj, x)\n",
    "        y = torch.matmul(y, self.weight)\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "        # y = self.linear(y)\n",
    "        y = self.sm(y)\n",
    "        _, i = torch.max(y, 1)\n",
    "        return i\n",
    "\n",
    "\n",
    "# Pool based on clusters\n",
    "class PoolClusters(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoolClusters, self).__init__()\n",
    "\n",
    "    def forward(self, x, sl):\n",
    "        cluster_ids = torch.unique(sl)\n",
    "        for cluster in cluster_ids:\n",
    "            indices = torch.nonzero(sl == cluster, as_tuple = True)[0]\n",
    "            cluster_mean = torch.mean(torch.index_select(x, 0, indices), dim = 0).unsqueeze(0)\n",
    "            try:\n",
    "                out = torch.cat((out, cluster_mean))\n",
    "            except Exception as e:\n",
    "                out = cluster_mean\n",
    "        return out\n",
    "\n",
    "\n",
    "def make_edge_list(neighbors_dict):\n",
    "    edge_list = []\n",
    "    for k,v in neighbors_dict.items():\n",
    "        [edge_list.append([k, cur_v]) for cur_v in v]\n",
    "    return edge_list\n",
    "\n",
    "def make_adj_matrix(edge_list, dim):\n",
    "    adj_matrix = np.zeros((dim, dim))\n",
    "    for edge in edge_list:\n",
    "        adj_matrix[edge[0]][edge[1]] = 1\n",
    "    for i in range(dim):\n",
    "        adj_matrix[i][i] = 1\n",
    "\n",
    "    return adj_matrix\n",
    "\n",
    "\n",
    "def fix_sl(sl):\n",
    "    cluster_ids = torch.unique(sl)\n",
    "    ref = dict(zip([i.item() for i in cluster_ids], [i for i in range(len(cluster_ids))]))\n",
    "    for i in cluster_ids:\n",
    "        sl[sl == i.item()] = ref[i.item()]\n",
    "    return sl\n",
    "\n",
    "\n",
    "# GCN basic operation\n",
    "class GenAdj(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GenAdj, self).__init__()\n",
    "\n",
    "    def forward(self, adj, sl, neighbors_dict):\n",
    "\n",
    "        sl = fix_sl(sl)\n",
    "\n",
    "        adj_map, new_neighbors_dict = {}, {}\n",
    "        cluster_ids = torch.unique(sl)\n",
    "\n",
    "        # Create a dictionary where each key is a node and the value is the cluster it belongs to\n",
    "        for cluster in cluster_ids:\n",
    "            indices = torch.nonzero(sl == cluster, as_tuple = True)[0]\n",
    "            for i in indices:\n",
    "                if i not in adj_map.keys():\n",
    "                    adj_map[i.item()] = cluster.item()\n",
    "\n",
    "        # Create a new neighbors dictionary for each of the clusters\n",
    "        for cluster in cluster_ids:\n",
    "            indices = torch.nonzero(sl == cluster, as_tuple = True)[0]\n",
    "\n",
    "            for i in indices:\n",
    "                temp = []\n",
    "                [temp.append(adj_map[i]) for i in neighbors_dict[i.item()] if i not in temp]\n",
    "                temp = list(set(temp)) # TO-DO: HERE CREATE SOME SORT OF SECONDARY DICTIONARY OR SOMETHING THAT COUNTS HOW MANY EDGES TO CREATE WEIGHTED ADJ MATRIX\n",
    "\n",
    "                new_neighbors_dict[cluster.item()] = temp\n",
    "\n",
    "        edge_list = make_edge_list(new_neighbors_dict)\n",
    "        adj_matrix = make_adj_matrix(edge_list, len(cluster_ids))\n",
    "\n",
    "        return torch.tensor(adj_matrix, dtype = torch.float32), new_neighbors_dict\n",
    "\n",
    "\n",
    "class diffPool(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_clusters, bias=True):\n",
    "        super(diffPool, self).__init__()\n",
    "\n",
    "        self.gc = GraphConv(input_dim = input_dim, output_dim = output_dim)\n",
    "        self.bn = torch.nn.BatchNorm1d(output_dim)\n",
    "        self.gen_assign = GenAssign(input_dim = output_dim, num_clusters = num_clusters)\n",
    "        self.pool = PoolClusters()\n",
    "        self.gen_adj = GenAdj()\n",
    "\n",
    "    def forward(self, x, adj, neighbors_dict):\n",
    "\n",
    "        # Generate node embeddings & normalize (no pooling yet)\n",
    "        x = self.gc(x, torch.tensor(adj, dtype = torch.float32))\n",
    "        x = self.bn(x)\n",
    "        # Create the assignment matrix (i.e. assign each node to a cluster)\n",
    "        sl = self.gen_assign(x, adj)\n",
    "        # Create the pooled feature matrix\n",
    "        x = self.pool(x, sl)\n",
    "        # Generate the new adjacency matrix\n",
    "        adj, neighbors_dict = self.gen_adj(adj, sl, neighbors_dict)\n",
    "        # print(neighbors_dict)\n",
    "\n",
    "        return x, adj, neighbors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diffPool(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_clusters, bias=True):\n",
    "        super(diffPool, self).__init__()\n",
    "\n",
    "        self.gc = GraphConv(input_dim = input_dim, output_dim = output_dim)\n",
    "        self.bn = torch.nn.BatchNorm1d(output_dim)\n",
    "        self.gen_assign = GenAssign(input_dim = output_dim, num_clusters = num_clusters)\n",
    "        self.pool = PoolClusters()\n",
    "        self.gen_adj = GenAdj()\n",
    "\n",
    "    def forward(self, x, adj, neighbors_dict):\n",
    "\n",
    "        # Generate node embeddings & normalize (no pooling yet)\n",
    "        x = self.gc(x, torch.tensor(adj, dtype = torch.float32))\n",
    "        x = self.bn(x)\n",
    "        # Create the assignment matrix (i.e. assign each node to a cluster)\n",
    "        sl = self.gen_assign(x, adj)\n",
    "        # Create the pooled feature matrix\n",
    "        x = self.pool(x, sl)\n",
    "        # Generate the new adjacency matrix\n",
    "        adj, neighbors_dict = self.gen_adj(adj, sl, neighbors_dict)\n",
    "        # print(neighbors_dict)\n",
    "\n",
    "        return x, adj, neighbors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spatialPool(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_clusters, resnet, bias=True):\n",
    "        super(spatialPool, self).__init__()\n",
    "\n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        self.avgpool = resnet.avgpool\n",
    "\n",
    "        self.dp1 = diffPool(input_dim = input_dim, output_dim = output_dim, num_clusters = 4)\n",
    "        self.dp2 = diffPool(input_dim = output_dim, output_dim = 128, num_clusters = 2)\n",
    "        self.linear = torch.nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x, adj, neighbors_dict):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        x, adj, neighbors_dict = self.dp1(x, adj, neighbors_dict)\n",
    "        x, adj, neighbors_dict = self.dp2(x, adj, neighbors_dict)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/hbaier/anaconda3/envs/caoe/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/home/hbaier/anaconda3/envs/caoe/lib/python3.7/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "9.768965721130371\n",
      "9.3634614944458\n",
      "10.230894088745117\n",
      "11.091619491577148\n",
      "9.675439834594727\n",
      "10.944665908813477\n",
      "/home/hbaier/anaconda3/envs/caoe/lib/python3.7/site-packages/torch/nn/modules/loss.py:96: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "9.51711368560791\n",
      "9.53965950012207\n",
      "9.348639488220215\n",
      "9.25556755065918\n",
      "9.153958320617676\n",
      "9.04182243347168\n",
      "8.917116165161133\n",
      "8.777771949768066\n",
      "8.621712684631348\n",
      "8.44686508178711\n",
      "8.251167297363281\n",
      "8.032574653625488\n",
      "7.789064884185791\n",
      "7.518643379211426\n",
      "7.219344139099121\n",
      "6.889239311218262\n",
      "6.5264434814453125\n",
      "6.129114627838135\n",
      "5.695463180541992\n",
      "5.223751068115234\n",
      "4.712294578552246\n",
      "4.159465312957764\n",
      "3.563692092895508\n",
      "2.923457622528076\n",
      "2.2372970581054688\n",
      "1.503800392150879\n",
      "0.7216091156005859\n",
      "0.11058425903320312\n",
      "0.7334394454956055\n",
      "1.1589994430541992\n",
      "1.4054012298583984\n",
      "1.493490219116211\n",
      "1.4447021484375\n",
      "1.2798280715942383\n",
      "1.0183334350585938\n",
      "0.6780424118041992\n",
      "0.2749919891357422\n",
      "0.17654800415039062\n",
      "0.4742259979248047\n",
      "0.6434907913208008\n",
      "0.703155517578125\n",
      "0.6672019958496094\n",
      "0.5460519790649414\n",
      "0.3474559783935547\n"
     ]
    }
   ],
   "source": [
    "r18 = models.resnet18(pretrained = True)\n",
    "model = spatialPool(input_dim = 512, output_dim = 256, num_clusters = 4, resnet = r18)\n",
    "criterion = torch.nn.L1Loss(reduction = \"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(0, 50):  \n",
    "\n",
    "    pred = model(final_im, torch.tensor(adj, dtype = torch.float32), neighbors_dict)\n",
    "    loss = criterion(pred, torch.tensor([10]))\n",
    "    print(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[10.2095]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}