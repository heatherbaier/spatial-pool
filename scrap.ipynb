{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd06e6e7e11ff29b7ea88d93fdd1bf54ac8bd20e793b837d22d51eef8412ed09bee",
   "display_name": "Python 3.7.10 64-bit ('caoe': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import tensorboardX\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# import cross_val\n",
    "# import encoders\n",
    "# import gen.feat as featgen\n",
    "# import gen.data as datagen\n",
    "# from graph_sampler import GraphSampler\n",
    "# import load_data\n",
    "# import util\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = np.array([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "       [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "       [0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.],\n",
    "       [0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
    "       [0., 0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.],\n",
    "       [0., 0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.],\n",
    "       [0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
    "       [0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
    "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.]])\n",
    "\n",
    "\n",
    "neighbors_dict = {0: [1, 2],\n",
    "                  1: [0, 2, 4, 5],\n",
    "                  2: [0, 1, 3, 4, 5, 6],\n",
    "                  3: [2, 5, 6],\n",
    "                  4: [1, 2, 5, 7, 8],\n",
    "                  5: [1, 2, 3, 4, 6, 7, 8, 9],\n",
    "                  6: [2, 3, 5, 8, 9],\n",
    "                  7: [4, 5, 8, 10],\n",
    "                  8: [4, 5, 6, 7, 9, 10, 11],\n",
    "                  9: [5, 6, 8, 10, 11],\n",
    "                  10: [7, 8, 9, 11, 12],\n",
    "                  11: [8, 9, 10, 12],\n",
    "                  12: [10, 11]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([14, 3, 256, 256])\ntorch.Size([15, 3, 256, 256])\ntorch.Size([16, 3, 256, 256])\ntorch.Size([17, 3, 256, 256])\ntorch.Size([18, 3, 256, 256])\ntorch.Size([19, 3, 256, 256])\ntorch.Size([20, 3, 256, 256])\ntorch.Size([21, 3, 256, 256])\ntorch.Size([22, 3, 256, 256])\ntorch.Size([23, 3, 256, 256])\ntorch.Size([24, 3, 256, 256])\ntorch.Size([25, 3, 256, 256])\ntorch.Size([26, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, utils, models\n",
    "\n",
    "to_tens = transforms.ToTensor()\n",
    "# del final_im\n",
    "\n",
    "for im in os.listdir(\"/home/hbaier/Desktop/graphPool/imagery\"):\n",
    "    cur_im = to_tens(Image.open(os.path.join(\"/home/hbaier/Desktop/graphPool/imagery\", im)).convert(\"RGB\")).unsqueeze(0)\n",
    "    try:\n",
    "        final_im = torch.cat((final_im, cur_im), dim = 0)\n",
    "        # print(\"try\")\n",
    "    except Exception as e:\n",
    "        final_im = cur_im\n",
    "        # print(e)\n",
    "    print(final_im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "class resnet18_mod(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, resnet):\n",
    "        super().__init__()\n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        self.avgpool = resnet.avgpool\n",
    "        self.fc = resnet.fc\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.flatten(start_dim=1)\n",
    "        # out = torch.cat((out, ids, coords), dim = 1)\n",
    "        # out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([26, 512])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "r18 = models.resnet18(pretrained = True)\n",
    "model = resnet18_mod(r18)\n",
    "input = model(final_im)#.detach().numpy()\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCN basic operation\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, bias=True):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.weight = nn.Parameter(torch.rand(input_dim, output_dim))#.cuda())\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.rand(output_dim))#.cuda())\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        y = torch.matmul(adj, x)\n",
    "        y = torch.matmul(y, self.weight)\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "        return y\n",
    "\n",
    "# Generate Assignment Matrix\n",
    "class GenAssign(nn.Module):\n",
    "    def __init__(self, input_dim, num_clusters, bias=True):\n",
    "        super(GenAssign, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_clusters = num_clusters\n",
    "        self.weight = nn.Parameter(torch.rand(input_dim, num_clusters))#.cuda())\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.rand(num_clusters))#.cuda())\n",
    "        else:\n",
    "            self.bias = None\n",
    "        # self.linear = torch.nn.Linear(input_dim, num_clusters)\n",
    "        self.sm = torch.nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        y = torch.matmul(adj, x)\n",
    "        y = torch.matmul(y, self.weight)\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "        # y = self.linear(y)\n",
    "        y = self.sm(y)\n",
    "        _, i = torch.max(y, 1)\n",
    "        return i\n",
    "\n",
    "\n",
    "# Pool based on clusters\n",
    "class PoolClusters(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PoolClusters, self).__init__()\n",
    "\n",
    "    def forward(self, x, sl):\n",
    "        cluster_ids = torch.unique(sl)\n",
    "        for cluster in cluster_ids:\n",
    "            indices = torch.nonzero(sl == cluster, as_tuple = True)[0]\n",
    "            cluster_mean = torch.mean(torch.index_select(x, 0, indices), dim = 0).unsqueeze(0)\n",
    "            try:\n",
    "                out = torch.cat((out, cluster_mean))\n",
    "            except Exception as e:\n",
    "                out = cluster_mean\n",
    "        return out\n",
    "\n",
    "\n",
    "def make_edge_list(neighbors_dict):\n",
    "    edge_list = []\n",
    "    for k,v in neighbors_dict.items():\n",
    "        [edge_list.append([k, cur_v]) for cur_v in v]\n",
    "    return edge_list\n",
    "\n",
    "def make_adj_matrix(edge_list, dim):\n",
    "    adj_matrix = np.zeros((dim, dim))\n",
    "    for edge in edge_list:\n",
    "        adj_matrix[edge[0]][edge[1]] = 1\n",
    "    for i in range(dim):\n",
    "        adj_matrix[i][i] = 1\n",
    "\n",
    "    return adj_matrix\n",
    "\n",
    "\n",
    "def fix_sl(sl):\n",
    "    cluster_ids = torch.unique(sl)\n",
    "    ref = dict(zip([i.item() for i in cluster_ids], [i for i in range(len(cluster_ids))]))\n",
    "    for i in cluster_ids:\n",
    "        sl[sl == i.item()] = ref[i.item()]\n",
    "    return sl\n",
    "\n",
    "\n",
    "# GCN basic operation\n",
    "class GenAdj(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GenAdj, self).__init__()\n",
    "\n",
    "    def forward(self, adj, sl, neighbors_dict):\n",
    "\n",
    "        sl = fix_sl(sl)\n",
    "\n",
    "        adj_map, new_neighbors_dict = {}, {}\n",
    "        cluster_ids = torch.unique(sl)\n",
    "\n",
    "        # Create a dictionary where each key is a node and the value is the cluster it belongs to\n",
    "        for cluster in cluster_ids:\n",
    "            indices = torch.nonzero(sl == cluster, as_tuple = True)[0]\n",
    "            for i in indices:\n",
    "                if i not in adj_map.keys():\n",
    "                    adj_map[i.item()] = cluster.item()\n",
    "\n",
    "        # Create a new neighbors dictionary for each of the clusters\n",
    "        for cluster in cluster_ids:\n",
    "            indices = torch.nonzero(sl == cluster, as_tuple = True)[0]\n",
    "\n",
    "            for i in indices:\n",
    "                temp = []\n",
    "                [temp.append(adj_map[i]) for i in neighbors_dict[i.item()] if i not in temp]\n",
    "                temp = list(set(temp)) # TO-DO: HERE CREATE SOME SORT OF SECONDARY DICTIONARY OR SOMETHING THAT COUNTS HOW MANY EDGES TO CREATE WEIGHTED ADJ MATRIX\n",
    "\n",
    "                new_neighbors_dict[cluster.item()] = temp\n",
    "\n",
    "        edge_list = make_edge_list(new_neighbors_dict)\n",
    "        adj_matrix = make_adj_matrix(edge_list, len(cluster_ids))\n",
    "\n",
    "        return torch.tensor(adj_matrix, dtype = torch.float32), new_neighbors_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diffPool(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_clusters, bias=True):\n",
    "        super(diffPool, self).__init__()\n",
    "\n",
    "        self.gc = GraphConv(input_dim = input_dim, output_dim = output_dim)\n",
    "        self.bn = torch.nn.BatchNorm1d(output_dim)\n",
    "        self.gen_assign = GenAssign(input_dim = output_dim, num_clusters = num_clusters)\n",
    "        self.pool = PoolClusters()\n",
    "        self.gen_adj = GenAdj()\n",
    "\n",
    "    def forward(self, x, adj, neighbors_dict):\n",
    "\n",
    "        # Generate node embeddings & normalize (no pooling yet)\n",
    "        x = self.gc(x, torch.tensor(adj, dtype = torch.float32))\n",
    "        x = self.bn(x)\n",
    "        # Create the assignment matrix (i.e. assign each node to a cluster)\n",
    "        sl = self.gen_assign(x, adj)\n",
    "        # Create the pooled feature matrix\n",
    "        x = self.pool(x, sl)\n",
    "        # Generate the new adjacency matrix\n",
    "        adj, neighbors_dict = self.gen_adj(adj, sl, neighbors_dict)\n",
    "        # print(neighbors_dict)\n",
    "\n",
    "        return x, adj, neighbors_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spatialPool(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_clusters, resnet, bias=True):\n",
    "        super(spatialPool, self).__init__()\n",
    "\n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        self.avgpool = resnet.avgpool\n",
    "\n",
    "        self.dp1 = diffPool(input_dim = input_dim, output_dim = output_dim, num_clusters = 4)\n",
    "        self.dp2 = diffPool(input_dim = output_dim, output_dim = 128, num_clusters = 2)\n",
    "        self.linear = torch.nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x, adj, neighbors_dict):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "\n",
    "        # print(x.shape)\n",
    "\n",
    "        x, adj, neighbors_dict = self.dp1(x, adj, neighbors_dict)\n",
    "        x, adj, neighbors_dict = self.dp2(x, adj, neighbors_dict)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'final_im' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5397ba4a6a23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbors_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_im' is not defined"
     ]
    }
   ],
   "source": [
    "r18 = models.resnet18(pretrained = True)\n",
    "model = spatialPool(input_dim = 512, output_dim = 256, num_clusters = 4, resnet = r18)\n",
    "criterion = torch.nn.L1Loss(reduction = \"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(0, 50):  \n",
    "\n",
    "    pred = model(final_im, torch.tensor(adj, dtype = torch.float32), neighbors_dict)\n",
    "    loss = criterion(pred, torch.tensor([10]))\n",
    "    print(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[10.2095]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}